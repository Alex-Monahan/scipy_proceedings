\section{Conclusion and Future Work}
The Semi-Supervised Semantic Annotator (S3A) is proposed to address the difficult task of pixel-level annotations of image data.
For high-resolution images with numerous complex regions of interest, existing labeling software faces performance bottlenecks attempting to extract ground-truth information.
Moreover, there is a lack of capabilities to convert such a labeling workflow into an automated procedure with feedback at every step.
Each of these challenges is overcome by various features within S3A specifically designed for such tasks.
As a result, S3A provides not only tremendous time savings during ground truth annotation, but also allows an annotation pipeline to be directly converted into a prediction scheme.
Furthermore, the rapid feedback accessible at every stage of annotation expedites prototyping of novel solutions to imaging domains in which few examples of prior work exist.
Nonetheless, multiple avenues exist for improving S3A's capabilities in each of these areas.
Several prominent future goals are highlighted in the following sections.

\subsection{Dynamic Algorithm Builder}
Presently, processing workflows can be specified in a sequential YAML file which describes each algorithm and their respective parameters.
However, this is not easy to adapt within S3A, especially by inexperienced annotators.
Future iterations of S3A will incoroprate graphical flowcharts which make this process drastically more intuitive and provide faster feedback.
Frameworks like Orange~\cite{demsar_orange_2013} perform this task well, and S3A would strongly benefit from adding the relevant capabilities.

\subsection{Image Navigation Assistance}
Several aspects of image navigation can be incorporated to simplify the handling of large images.
For instance, a ``minimap" tool would allow users to maintain a global image perspective while making local edits.
Furthermore, this sense of scale aids intuition of how many regions of similar component density, color, etc.
exist within the entire image.

Second, multiple strategies for annotating large images leverage a windowing approach, where they will divide the total image into several smaller pieces in a gridlike fashion.
While this has its disadvantages, it is fast, easy to automate, and produces reasonable results depending on the initial image complexity \cite{Vigueras_fullCnnCornealSegmentation}.
Hence, these methods would be significantly easier to incorporate into S3A if a generalized windowing framework was incorporated which allows users to specify all necessary parameters such as window overlap, size, sampling frequency, etc.
A preliminary version of this is implemented for categorical-based model prediction, but a more robust feature set for interactive segmentation is strongly preferable.

\subsection{Aggregation of Human Annotation Habits}
Several times, it has been noted that manual segmentation of image data is not a feasible or scalable approach for remotely large datasets.
However, there are multiple cases in which human intuition can greatly outperform even complex neural networks, depending on the specific segmentation challenge \cite{Russakovsky_humanCollabAnnotation2015}.
For this reason, it would be ideal to capture data points possessing information about the human decision-making process and apply them to images at scale.
This may include taking into account human labeling time per class, hesitation between clicks, relationship between shape boundary complexity and instance quantity, and more.
By aggregating such statistics, a pattern may arise which can be leveraged as an additional automated annotation technique.